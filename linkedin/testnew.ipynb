{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eb79271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Profile already scraped in this session, skipping scraper\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangMem procedural learning system initialized successfully.\n",
      "--- Testing Enhanced Thread-Based Procedural Learning ---\n",
      "=== TESTING THREAD-BASED PROCEDURAL LEARNING ===\n",
      "=== TEST COMPLETE ===\n",
      "\n",
      "--- Testing Graph with All Fixes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:LLM call failed on attempt 1: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "WARNING:root:LLM call failed on attempt 2: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 12\n",
      "}\n",
      "]\n",
      "WARNING:root:LLM call failed on attempt 3: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 10\n",
      "}\n",
      "]\n",
      "ERROR:root:Circuit opened after 3 consecutive failures.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Graph execution successful\n",
      "Messages generated: 2815\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import operator\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.types import Command, interrupt\n",
    "from pymongo import MongoClient\n",
    "from langgraph.checkpoint.mongodb import MongoDBSaver\n",
    "from langgraph.store.mongodb.base import MongoDBStore\n",
    "\n",
    "\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import traceback\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "import functools\n",
    "import logging\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from langmem import (\n",
    "    create_memory_store_manager,\n",
    "    create_prompt_optimizer,\n",
    "    create_manage_memory_tool,\n",
    "    create_search_memory_tool\n",
    ")\n",
    "\n",
    "load_dotenv()  # <-- MUST be at the very top before any os.getenv\n",
    "\n",
    "APIFY_TOKEN = os.getenv(\"APIFY_API_KEY\")  #\n",
    "\n",
    "# Set up basic logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Circuit breaker state\n",
    "circuit_open = False\n",
    "failure_count = 0\n",
    "failure_threshold = 3  # Open circuit after 3 consecutive failures\n",
    "circuit_reset_time = 30  # seconds\n",
    "last_failure_time = 0\n",
    "\n",
    "\n",
    "# --- Define the Pydantic Schema right after your AgentState class ---\n",
    "class CareerMemory(BaseModel):\n",
    "    \"\"\"A structured memory for storing insights about a user's career planning session.\"\"\"\n",
    "    career_goal: str = Field(description=\"The user's specific career objective or transition goal\")\n",
    "    timeline: Optional[str] = Field(description=\"Timeframe mentioned for achieving the goal\")\n",
    "    current_role: Optional[str] = Field(description=\"User's current position/role\")\n",
    "    target_role: Optional[str] = Field(description=\"Desired position/role\")\n",
    "    key_skills_needed: Optional[List[str]] = Field(description=\"Important skills mentioned or needed\")\n",
    "    learning_preferences: Optional[str] = Field(description=\"Preferred learning methods or platforms\")\n",
    "    industry_focus: Optional[str] = Field(description=\"Target industry or domain of interest\")\n",
    "    success_strategies: Optional[str] = Field(description=\"Approaches that have worked well for similar goals\")\n",
    "    common_obstacles: Optional[str] = Field(description=\"Challenges typically faced in this type of transition\")\n",
    "    resource_recommendations: Optional[str] = Field(description=\"Specific courses, tools, or resources that proved effective\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def llm_call_with_retry_circuit(prompt: str, max_retries=3, retry_delay=2):\n",
    "    \"\"\"\n",
    "    Wrapper for model.generate_content with:\n",
    "    - Retry on transient errors\n",
    "    - Circuit breaker to stop repeated failures\n",
    "    - Token/cost logging\n",
    "    \"\"\"\n",
    "    global circuit_open, failure_count, last_failure_time\n",
    "\n",
    "    # Circuit breaker check\n",
    "    if circuit_open:\n",
    "        if time.time() - last_failure_time < circuit_reset_time:\n",
    "            logging.warning(\"Circuit open. Skipping LLM call.\")\n",
    "            raise RuntimeError(\"Circuit open due to repeated failures\")\n",
    "        else:\n",
    "            logging.info(\"Resetting circuit breaker.\")\n",
    "            circuit_open = False\n",
    "            failure_count = 0\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            res = model.generate_content(prompt)\n",
    "\n",
    "            # Logging token/cost info if available\n",
    "            if hasattr(res, \"usage\"):\n",
    "                tokens = res.usage.get(\"total_tokens\", \"N/A\")\n",
    "                cost = tokens * 0.00001  # Example: adjust based on model pricing\n",
    "                logging.info(\n",
    "                    f\"LLM call successful | Tokens used: {tokens} | Est. cost: ${cost:.6f}\"\n",
    "                )\n",
    "\n",
    "            # Reset failure count on success\n",
    "            failure_count = 0\n",
    "            return res\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"LLM call failed on attempt {attempt}: {e}\")\n",
    "            failure_count += 1\n",
    "            last_failure_time = time.time()\n",
    "            if failure_count >= failure_threshold:\n",
    "                circuit_open = True\n",
    "                logging.error(\n",
    "                    f\"Circuit opened after {failure_count} consecutive failures.\"\n",
    "                )\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                raise RuntimeError(f\"LLM call failed after {max_retries} attempts: {e}\")\n",
    "\n",
    "\n",
    "# Try to use MongoDB persistence, fallback to memory if not available\n",
    "try:\n",
    "    mongo_uri = os.getenv(\"MONGODB_URI\", \"mongodb://localhost:27017\")\n",
    "    mongo_client = MongoClient(mongo_uri)\n",
    "    mongo_client.admin.command(\"ping\")\n",
    "\n",
    "    # Define the LLM instance once\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # 1. Graph Checkpointer (CORRECTED INSTANTIATION)\n",
    "    # We instantiate MongoDBSaver directly instead of using the context manager.\n",
    "    checkpoint_db = mongo_client[\"career_bot_checkpoints\"]\n",
    "    checkpointer = MongoDBSaver(\n",
    "    client=mongo_client,  # <-- THIS IS THE MISSING ARGUMENT\n",
    "    collection=checkpoint_db[\"checkpoints\"]\n",
    ")\n",
    "\n",
    "    # 2. LangMem Memory Store\n",
    "    db = mongo_client[\"career_bot_memories\"]\n",
    "    memory_store = MongoDBStore(collection=db[\"procedural_memories\"])\n",
    "\n",
    "    # 3. Create the Memory Store Manager - The Core Component\n",
    "    # This single manager handles persistence, extraction, and updates.\n",
    "    memory_store_manager = create_memory_store_manager(\n",
    "        llm,                      # The LLM is the required positional-only first argument\n",
    "        schemas=[CareerMemory],   # The Pydantic class defines the shape of our memories\n",
    "        store=memory_store\n",
    "    )\n",
    "\n",
    "    # 4. Create the other tools as requested\n",
    "    prompt_optimizer = create_prompt_optimizer(llm)\n",
    "    manage_memory_tool = create_manage_memory_tool(memory_store_manager)\n",
    "    search_memory_tool = create_search_memory_tool(memory_store_manager)\n",
    "\n",
    "    print(\"✅ LangMem procedural learning system initialized successfully.\")\n",
    "    LANGMEM_AVAILABLE = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ LangMem initialization failed: {e}\\n{traceback.format_exc()}\")\n",
    "    # Your original fallback logic...\n",
    "    from langgraph.checkpoint.memory import MemorySaver\n",
    "    checkpointer = MemorySaver()\n",
    "    memory_store_manager = None\n",
    "    prompt_optimizer = None\n",
    "    manage_memory_tool = None\n",
    "    search_memory_tool = None\n",
    "    LANGMEM_AVAILABLE = False\n",
    "\n",
    "\n",
    "import google.generativeai as genai\n",
    "from scraper_utils import scrape_and_clean_profile\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"models/gemini-1.5-flash\")\n",
    "\n",
    "\n",
    "class AgentState(TypedDict, total=False):\n",
    "    messages: Annotated[list[BaseMessage], operator.add]\n",
    "    profile_data: Annotated[dict, lambda _, x: x]\n",
    "    current_job_description: Annotated[Optional[str], lambda _, x: x]\n",
    "    linkedin_url: Annotated[Optional[str], lambda _, x: x]\n",
    "    thread_id: Annotated[Optional[str], lambda _, x: x]  \n",
    "    websearch_results: Annotated[list, lambda _, x: x]\n",
    "    websearch_summary: Annotated[list, lambda _, x: x]\n",
    "    # FIX 1: Add flag to track if profile was already scraped\n",
    "    profile_scraped: Annotated[bool, lambda _, x: x]\n",
    "\n",
    "\n",
    "from apify_client import ApifyClient\n",
    "import time\n",
    "\n",
    "# FIX 3: Improved websearch with better error handling and link extraction\n",
    "def websearch_mcp_node(state: AgentState) -> dict:\n",
    "    messages = state.get(\"messages\", [])\n",
    "    messages.append(AIMessage(\"🔍 Fetching web data...\"))\n",
    "\n",
    "    query = \"\"\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            query = msg.content.strip()\n",
    "            break\n",
    "\n",
    "    if not query:\n",
    "        messages.append(AIMessage(\"⚠ No query provided for web search.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return state\n",
    "\n",
    "    api_token = os.getenv(\"APIFY_API_KEY\")\n",
    "    if not api_token:\n",
    "        messages.append(AIMessage(\"❌ Apify API token not configured.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return state\n",
    "\n",
    "    client = ApifyClient(api_token)\n",
    "    actor_id = \"apify/google-search-scraper\"\n",
    "    input_data = {\"queries\": [query], \"maxPagesPerQuery\": 1, \"resultsPerPage\": 5, \"countryCode\": \"US\", \"languageCode\": \"en\"}\n",
    "    max_retries = 3\n",
    "    retry_delay = 2\n",
    "    results = []\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            logging.info(f\"Starting Apify web search for: {query}\")\n",
    "            run = client.actor(actor_id).call(run_input=input_data)\n",
    "            dataset_items = client.dataset(run[\"defaultDatasetId\"]).list_items().items\n",
    "            logging.info(f\"Retrieved {len(dataset_items)} items from Apify\")\n",
    "            \n",
    "            for item in dataset_items:\n",
    "                search_results = item.get(\"searchResults\", [])\n",
    "                for result in search_results:\n",
    "                    results.append({\"title\": result.get(\"title\", \"\"), \"link\": result.get(\"url\", \"\"), \"snippet\": result.get(\"description\", \"\")})\n",
    "\n",
    "            if results:\n",
    "                messages.append(AIMessage(f\"🔍 WebSearch results fetched via Apify ({len(results)} results):\\n\" + \"\\n\".join([f\"- {r['title']}: {r['link']}\" for r in results[:3]])))\n",
    "                logging.info(f\"Successfully found {len(results)} web search results\")\n",
    "            else:\n",
    "                messages.append(AIMessage(\"⚠ No search results found.\"))\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Apify search attempt {attempt} failed: {e}\")\n",
    "            if attempt < max_retries:\n",
    "                messages.append(AIMessage(f\"⚠ Apify attempt {attempt} failed. Retrying...\"))\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                messages.append(AIMessage(f\"❌ Apify WebSearch failed after {max_retries} attempts: {e}\"))\n",
    "\n",
    "    state[\"messages\"] = messages\n",
    "    state[\"websearch_results\"] = results\n",
    "    return state\n",
    "\n",
    "def enrich_websearch_node(state):\n",
    "    messages = state.get(\"messages\", [])\n",
    "    results = state.get(\"websearch_results\", [])\n",
    "    if not results:\n",
    "        messages.append(AIMessage(\"⚠ No search results to enrich.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return state\n",
    "\n",
    "    summary = []\n",
    "    for r in results:\n",
    "        content = r.get(\"snippet\") or r.get(\"content\") or r.get(\"description\", \"\")\n",
    "        if not content and r.get(\"link\"):\n",
    "            try:\n",
    "                import requests\n",
    "                response = requests.get(r[\"link\"], timeout=10, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'})\n",
    "                content = response.text[:2000]\n",
    "            except Exception as e:\n",
    "                content = f\"Could not fetch content: {e}\"\n",
    "        try:\n",
    "            if content and len(content) > 50:\n",
    "                summary_prompt = f\"Summarize the key points for career planning from this content:\\n\\n{content[:1500]}\"\n",
    "                # - MODIFICATION: Using the synchronous LLM call\n",
    "                res = llm_call_with_retry_circuit(summary_prompt)\n",
    "                summary_text = res.text\n",
    "            else:\n",
    "                summary_text = content or \"No content available\"\n",
    "            summary.append({\"title\": r[\"title\"], \"link\": r[\"link\"], \"summary\": summary_text[:500]})\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error enriching search result: {e}\")\n",
    "            summary.append({\"title\": r[\"title\"], \"link\": r[\"link\"], \"summary\": f\"❌ Could not summarize: {e}\"})\n",
    "\n",
    "    messages.append(AIMessage(f\"✅ Search results enriched with AI summaries ({len(summary)} results).\"))\n",
    "    state[\"messages\"] = messages\n",
    "    state[\"websearch_summary\"] = summary\n",
    "    return state\n",
    "\n",
    "\n",
    "def store_websearch_node(state: AgentState) -> dict:\n",
    "    try:\n",
    "        client = MongoClient(os.getenv(\"MONGODB_URI\", \"mongodb://localhost:27017\"))\n",
    "        db = client[\"career_bot\"]\n",
    "        collection = db[\"websearch\"]\n",
    "        results = state.get(\"websearch_summary\", [])\n",
    "        if results:\n",
    "            import datetime\n",
    "            for result in results:\n",
    "                result[\"timestamp\"] = datetime.datetime.utcnow().isoformat()\n",
    "                result[\"thread_id\"] = state.get(\"thread_id\", \"unknown\")\n",
    "            collection.insert_many(results)\n",
    "            state[\"messages\"].append(AIMessage(f\"💾 Stored {len(results)} search results in DB.\"))\n",
    "        else:\n",
    "            state[\"messages\"].append(AIMessage(\"⚠ Nothing to store.\"))\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error storing websearch results: {e}\")\n",
    "        state[\"messages\"].append(AIMessage(\"⚠ Failed to store search results.\"))\n",
    "    return state\n",
    "\n",
    "# FIX 1: Improved LinkedIn scraper that only runs when needed\n",
    "def linkedin_scraper_node(state: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Scrapes LinkedIn profile URL only if not already scraped in this session.\n",
    "    \"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    thread_id = state.get(\"thread_id\", \"default_thread\")\n",
    "    profile_scraped = state.get(\"profile_scraped\", False)\n",
    "    existing_profile = state.get(\"profile_data\")\n",
    "\n",
    "    # FIX 1: Skip scraping if profile already exists and was scraped\n",
    "    if profile_scraped and existing_profile:\n",
    "        logging.info(\"Profile already scraped in this session, skipping scraper\")\n",
    "        return Command(goto=[\"career_qa_router\"], update=state)\n",
    "\n",
    "    linkedin_url = state.get(\"linkedin_url\", \"\").strip()\n",
    "\n",
    "    if not linkedin_url:\n",
    "        messages.append(AIMessage(\"Please provide a LinkedIn profile URL to begin.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"continue_chat\")\n",
    "\n",
    "    messages.append(AIMessage(\"Scraping your LinkedIn profile...\"))\n",
    "\n",
    "    try:\n",
    "        scraped_profile = scrape_and_clean_profile(\n",
    "            linkedin_url=linkedin_url, api_token=os.getenv(\"APIFY_API_KEY\")\n",
    "        )\n",
    "\n",
    "        if not scraped_profile:\n",
    "            messages.append(AIMessage(\"Failed to extract profile. Try again.\"))\n",
    "            state[\"messages\"] = messages\n",
    "            return interrupt(\"continue_chat\")\n",
    "\n",
    "        messages.append(AIMessage(\"Profile successfully scraped!\"))\n",
    "        state[\"profile_data\"] = scraped_profile\n",
    "        state[\"profile_scraped\"] = True  # FIX 1: Mark as scraped\n",
    "        state[\"messages\"] = messages\n",
    "        state[\"thread_id\"] = thread_id\n",
    "\n",
    "    except Exception as e:\n",
    "        messages.append(AIMessage(f\"Error scraping LinkedIn profile: {e}\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"continue_chat\")\n",
    "\n",
    "    return Command(goto=[\"career_qa_router\"], update=state)\n",
    "\n",
    "\n",
    "def career_qa_router(state: AgentState) -> Command:\n",
    "    profile = state.get(\"profile_data\", {})\n",
    "    jd = state.get(\"current_job_description\", \"\")\n",
    "    messages = state.get(\"messages\", [])\n",
    "    question = \"\"\n",
    "\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            question = msg.content.strip()\n",
    "            break\n",
    "\n",
    "    if question.lower() in {\"quit\", \"exit\", \"stop\"}:\n",
    "        messages.append(AIMessage(\"Okay, ending the conversation.\"))\n",
    "        return Command(goto=END, update={\"messages\": messages})\n",
    "\n",
    "    if \"job description:\" in question.lower():\n",
    "        messages.append(AIMessage(\"Got your new job description.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        state[\"current_job_description\"] = question\n",
    "        return interrupt(\"continue_chat\")\n",
    "\n",
    "    # FIX 3: Check if web search is needed for this query\n",
    "    if any(keyword in question.lower() for keyword in [\n",
    "        \"course\", \"learn\", \"certification\", \"training\", \"resource\", \n",
    "        \"website\", \"online\", \"platform\", \"bootcamp\", \"tutorial\"\n",
    "    ]):\n",
    "        logging.info(\"Query requires web search, routing to websearch first\")\n",
    "        return Command(goto=\"websearch_mcp\", update=state)\n",
    "\n",
    "    history = \"\\n\".join(\n",
    "        f\"Human: {m.content}\" if isinstance(m, HumanMessage) else f\"AI: {m.content}\"\n",
    "        for m in messages[-5:]\n",
    "    )\n",
    "    prompt = f\"\"\"\n",
    "    {history}\n",
    "You are a routing agent. Decide which module should handle the user's latest question.\n",
    "\n",
    "Return one of:\n",
    "- analyze_profile\n",
    "- job_fit_agent\n",
    "- enhance_profile\n",
    "- career_plan\n",
    "- general_qa\n",
    "\n",
    "DO NOT GUESS. Use the following rules:\n",
    "\n",
    "---\n",
    "\n",
    "ROUTE TO: analyze_profile\n",
    "→ If the user wants a LinkedIn/resume/profile review, feedback, strengths, weaknesses, or audit.\n",
    "\n",
    "Examples:\n",
    "- \"Can you review my LinkedIn?\"\n",
    "- \"What are my strengths and weaknesses?\"\n",
    "- \"Audit my profile\"\n",
    "- Or any other question that implies analyzing the profile.\n",
    "---\n",
    "\n",
    "ROUTE TO: job_fit_agent\n",
    "→ If the user says anything like:\n",
    "- \"Does my profile match this JD?\"\n",
    "- \"Am I eligible for this job?\"\n",
    "- \"Score me against this role\"\n",
    "- Or any other question that implies matching the profile to a job description.\n",
    "\n",
    "Only route here if a job description was recently provided.\n",
    "\n",
    "---\n",
    "\n",
    "ROUTE TO: enhance_profile\n",
    "→ If the user asks for:\n",
    "- Rewriting/resume improvement\n",
    "- Profile optimization\n",
    "- \"Improve my About section\"\n",
    "- \"Rewrite my Experience bullets\"\n",
    "- Or any other question that implies enhancing the profile.\n",
    "\n",
    "---\n",
    "\n",
    "ROUTE TO: career_plan\n",
    "→ If the user wants a career plan, roadmap, or action plan.\n",
    "\n",
    "Examples:\n",
    "- \"Create a career plan for me\"\n",
    "- \"Give me a roadmap to become a data scientist\"\n",
    "- \"I want a 30-60-90 day plan\"\n",
    "- \"Help me plan my career transition\"\n",
    "- Or any other question that implies creating a structured career plan.\n",
    "\n",
    "---\n",
    "\n",
    "ROUTE TO: general_qa\n",
    "→ All other general career questions.\n",
    "\n",
    "Examples:\n",
    "- \"What kind of roles should I target?\"\n",
    "- \"How do I switch fields?\"\n",
    "- \"What are good certifications for data science?\"\n",
    "- \"How do I get into startups?\"\n",
    "- Or any other question that doesn't fit the above categories.\n",
    "\n",
    "---\n",
    "\n",
    "USER QUESTION:\n",
    "{question}\n",
    "\n",
    "Just respond with ONE of:\n",
    "analyze_profile, job_fit_agent, enhance_profile, career_plan, general_qa\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        result = llm_call_with_retry_circuit(prompt)\n",
    "        decision = result.text.strip().lower()\n",
    "\n",
    "        if decision in {\n",
    "            \"analyze_profile\",\n",
    "            \"job_fit_agent\",\n",
    "            \"enhance_profile\",\n",
    "            \"career_plan\",\n",
    "            \"general_qa\",\n",
    "        }:\n",
    "            state[\"messages\"] = messages\n",
    "\n",
    "            return Command(\n",
    "                goto=decision if decision != \"general_qa\" else \"general_qa_node\",\n",
    "                update=state\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            messages.append(AIMessage(\"⚠ I didn't understand. Try rephrasing.\"))\n",
    "            state[\"messages\"] = messages\n",
    "            return interrupt(\"continue_chat\")\n",
    "    except Exception as e:\n",
    "        messages.append(AIMessage(f\"⚠ Routing error: {e}\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"continue_chat\")\n",
    "\n",
    "\n",
    "def analyze_profile_node(state: AgentState) -> dict:\n",
    "    profile = state.get(\"profile_data\")\n",
    "    messages = state[\"messages\"]\n",
    "    if not profile:\n",
    "        messages.append(AIMessage(\"⚠ No profile data found to analyze.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"continue_chat\")\n",
    "\n",
    "    profile_text = \"\\n\".join(f\"{k}: {v}\" for k, v in profile.items())\n",
    "    history = \"\\n\".join(\n",
    "        f\"Human: {m.content}\" if isinstance(m, HumanMessage) else f\"AI: {m.content}\"\n",
    "        for m in messages[-5:]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "{history}\n",
    "        You are a highly experienced career coach and tech recruiter who has reviewed over 10,000 LinkedIn profiles.\n",
    "\n",
    "        Your job is to critically evaluate the following LinkedIn profile and return a brutally honest, section-wise analysis.\n",
    "\n",
    "        Use the following criteria for evaluation:\n",
    "        1. Clarity and professionalism of writing\n",
    "        2. Technical and strategic relevance of content\n",
    "        3. Recruiter impression: Would you shortlist this profile?\n",
    "\n",
    "        ---\n",
    "\n",
    "        {profile_text}\n",
    "\n",
    "        ---\n",
    "\n",
    "        ### Return output in the following structure:\n",
    "\n",
    "        # LinkedIn Profile Audit\n",
    "\n",
    "        ## Strengths  \n",
    "        List 3–5 strengths that stand out across the profile.\n",
    "\n",
    "        ## Weaknesses  \n",
    "        List 3–5 major weaknesses holding the profile back.\n",
    " ## Section-by-Section Evaluation  \n",
    "        For each section (About, Experience, Projects, Education, Skills, etc.), write:\n",
    "\n",
    "        - Give a quality score: ✅ Strong / ⚠ Needs improvement / ❌ Missing  \n",
    "        - Provide 2–3 suggestions to improve the section (content, phrasing, structure)  \n",
    "        - Use clean formatting: bold headings, bullet points, and avoid unnecessary repetition.\n",
    "\n",
    "        Constraints:\n",
    "        - Max 4 bullet points per section  \n",
    "        - Each bullet: <30 words  \n",
    "        - Total section feedback: <100 words\n",
    "\n",
    "        ## Top 3 Improvements You Must Make Now  \n",
    "        Each point must be:\n",
    "        - Brutally specific  \n",
    "        - Directly actionable  \n",
    "        - One line only\n",
    "        \n",
    "        Precautions:\n",
    "        - Do not hallucinate and stay within context.\n",
    "        - If the user asks for/about a specific section (e.g., \"improve my projects\"), focus only on that section.\n",
    "        \n",
    "        Begin now.\n",
    "        \"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        res = llm_call_with_retry_circuit(prompt)\n",
    "        messages.append(AIMessage(res.text))\n",
    "        state[\"messages\"] = messages\n",
    "    except Exception as e:\n",
    "        messages.append(AIMessage(f\"❌ Error: {e}\"))\n",
    "        state[\"messages\"] = messages\n",
    "\n",
    "    return interrupt(\"continue_chat\")\n",
    "\n",
    "\n",
    "def job_fit_agent_node(state: AgentState) -> dict:\n",
    "    profile = state.get(\"profile_data\")\n",
    "    jd = state.get(\"current_job_description\", \"\")\n",
    "    messages = state[\"messages\"]\n",
    "    if not profile or not jd:\n",
    "        messages.append(AIMessage(\"⚠ Missing profile or job description.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"continue_chat\")\n",
    "\n",
    "    profile_text = \"\\n\".join(f\"{k}: {v}\" for k, v in profile.items())\n",
    "    history = \"\\n\".join(\n",
    "        f\"Human: {m.content}\" if isinstance(m, HumanMessage) else f\"AI: {m.content}\"\n",
    "        for m in messages[-5:]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "{history}\n",
    "        You are a highly experienced AI Job Fit Evaluator trained on thousands of hiring decisions across several job roles.\n",
    "        Your job is to evaluate how well the candidate's profile matches the given job description.       \n",
    "        ---\n",
    "\n",
    "        JOB DESCRIPTION:\n",
    "        {jd}\n",
    "\n",
    "        CANDIDATE PROFILE:\n",
    "        {profile_text}\n",
    "\n",
    "        ---\n",
    "\n",
    "        TASKS:\n",
    "        1. Evaluate the fitness of the candidate for this job role using industry-standard evaluation practices (skills, experience, keywords, impact, achievements, and alignment).\n",
    "        2. Return a Job Match Score out of 100, and explain how you arrived at it with specific reasoning.\n",
    "        3. List 3–5 strengths from the candidate's profile that match the job expectations.\n",
    "        4. Suggest 3–5 concrete improvements – these could include skill gaps, experience tweaks, weak areas in phrasing, or missing proof of impact.\n",
    "  5. Only evaluate against the given job role. Do not assume adjacent job titles are valid matches.\n",
    "        6. If the candidate seems overqualified or underqualified, clearly state it and explain how that affects the match.\n",
    "\n",
    "        ---\n",
    "\n",
    "        OUTPUT FORMAT:\n",
    "        # 🎯 Job Fit Evaluation\n",
    "\n",
    "        ## ✅ Job Match Score: XX/100\n",
    "        - One-line explanation of the score.\n",
    "        - 2–3 bullets with specific justification.\n",
    "\n",
    "        ## 🟩 Strengths\n",
    "        - Point 1 (aligned with JD)\n",
    "        - Point 2\n",
    "        - Point 3  \n",
    "        (Each point ≤ 40 words)\n",
    "\n",
    " ## 🟥 Weaknesses\n",
    "        - specify the top 3-4 points as to why this profile doesn't match the job or will get rejected even if applied and this analysis must be honest and brutal\n",
    "        (Each point ≤ 40 words)\n",
    "\n",
    "        ## 🛠 Improvements to Increase Match Score\n",
    "        - Point 1 (what to improve and how)\n",
    "        - Point 2\n",
    "        - Point 3  \n",
    "        (Each point ≤ 25 words)\n",
    "\n",
    "        ## 📌 Verdict\n",
    "        Clearly say if the candidate is a strong match, weak match, or needs improvement to apply. Give a one-liner summary.\n",
    "        \n",
    "        Precautions:\n",
    "        - Do not hallucinate and stay within context.\n",
    "        - If the user asks for/about a specific section (e.g., \"improve my projects\"), focus only on that section.\n",
    "        \n",
    "        Begin now.\n",
    "\"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        res = llm_call_with_retry_circuit(prompt)\n",
    "\n",
    "        messages.append(AIMessage(res.text))\n",
    "        state[\"messages\"] = messages\n",
    "    except Exception as e:\n",
    "        messages.append(AIMessage(f\"❌ Error: {e}\"))\n",
    "        state[\"messages\"] = messages\n",
    "\n",
    "    return interrupt(\"continue_chat\")\n",
    "\n",
    "\n",
    "def enhance_profile_node(state: AgentState) -> dict:\n",
    "    profile = state.get(\"profile_data\")\n",
    "    jd = state.get(\"current_job_description\", \"\")\n",
    "    messages = state[\"messages\"]\n",
    "    if not profile:\n",
    "        messages.append(AIMessage(\"⚠ No profile found to enhance.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"continue_chat\")\n",
    "\n",
    "    profile_text = \"\\n\".join(f\"{k}: {v}\" for k, v in profile.items())\n",
    "    history = \"\\n\".join(\n",
    "        f\"Human: {m.content}\" if isinstance(m, HumanMessage) else f\"AI: {m.content}\"\n",
    "        for m in messages[-5:]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "{history}\n",
    "        You are a highly experienced LinkedIn Profile Optimization AI, trained on millions of real-world hiring patterns across top companies like Google, Amazon, Meta, and startups. Your task is to analyze and rewrite the user's LinkedIn profile to improve clarity, strength, and impact.\n",
    "\n",
    "        CONTEXT:\n",
    "        - The user may or may not have shared a job description.\n",
    "        - They might be asking to improve a specific section only (e.g., \"improve my projects to match this JD\").\n",
    "        - You should infer goals from the user's question and adjust accordingly.\n",
    "        - If any question is related to the job description/JD then consider that and then provide an output\n",
    "\n",
    "        CURRENT PROFILE:\n",
    "        {profile_text}  \n",
    "\n",
    "        JOB DESCRIPTION/JD:\n",
    "        {jd}\n",
    "  TASKS:\n",
    "        1. Identify weak sections and rewrite them to be stronger, more professional, and better aligned with either:\n",
    "            - the job description (if provided), or\n",
    "            - general hiring best practices (if no JD is given).\n",
    "        2. Preserve all factual details. Do NOT add imaginary experiences.\n",
    "        3. Use bullet points only where appropriate (e.g., Experience, Projects).\n",
    "        4. Each bullet must be ≤ 25 words, and **max 4 bullets per section.\n",
    "        5. For the \"About\" section, limit to 2–3 tight paragraphs, total **≤ 250 words.\n",
    "        6. Add impactful verbs, metrics, and proof of value wherever possible.\n",
    "        7. If the user requested only a section enhancement (e.g., just projects), modify only that section.\n",
    "        8. If the user asks for a specific section (e.g., \"improve my projects\"), focus only on that section, DO NOT TALK ABOUT OTHER SECTIONS.\n",
    "\n",
    "        FORMAT:\n",
    "        Return the improved sections in clean Markdown format.\n",
    "        - Use bold section titles.\n",
    "        - Show only modified sections – skip untouched ones to save tokens.\n",
    "        - Make sure the rewritten content feels real, focused, and hiring-ready.\n",
    "\n",
    "Precautions:\n",
    "        - Do not hallucinate and stay within context.\n",
    "        - If the user asks for/about a specific section (e.g., \"improve my projects\"), focus only on that section.\n",
    "\n",
    "        Begin now.\n",
    "\"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        res = llm_call_with_retry_circuit(prompt)\n",
    "\n",
    "        messages.append(AIMessage(res.text))\n",
    "        state[\"messages\"] = messages\n",
    "    except Exception as e:\n",
    "        messages.append(AIMessage(f\"❌ Error: {e}\"))\n",
    "        state[\"messages\"] = messages\n",
    "\n",
    "    return interrupt(\"continue_chat\")\n",
    "\n",
    "\n",
    "def general_qa_node(state: AgentState) -> dict:\n",
    "    messages = state[\"messages\"]\n",
    "    question = \"\"\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            question = msg.content.strip()\n",
    "            break\n",
    "\n",
    "    history = \"\\n\".join(\n",
    "        f\"Human: {m.content}\" if isinstance(m, HumanMessage) else f\"AI: {m.content}\"\n",
    "        for m in messages[-5:]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful, concise, and highly experienced career guidance assistant.\n",
    "\n",
    "Your task is to answer general career-related questions from users\n",
    "\n",
    "The user may ask about:\n",
    "- Career advice\n",
    "- Interview preparation\n",
    "- Certifications\n",
    "- Job search strategy\n",
    "- Skill-building\n",
    "- Remote work\n",
    "- Career switches\n",
    "- Industry trends\n",
    "- Anything else loosely related to career growth\n",
    "\n",
    "---\n",
    "\n",
    "USER CONTEXT (optional):\n",
    "{history}\n",
    "\n",
    "PROFILE DATA:\n",
    "{state.get(\"profile_data\", \"N/A\")}\n",
    "\n",
    "JOB DESCRIPTION (if any):\n",
    "{state.get(\"current_job_description\", \"N/A\")}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "---\n",
    "\n",
    "### Answer Guidelines:\n",
    "\n",
    "- Answer clearly and concisely.\n",
    "- Prioritize useful, actionable advice.\n",
    "- If the question is vague or broad, ask a clarifying follow-up.\n",
    "- Keep the tone supportive but professional.\n",
    "- Do not suggest uploading a resume or LinkedIn again.\n",
    "- If you detect the user is stressed, confused, or unsure, acknowledge that supportively.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Format:\n",
    "\n",
    "Respond in clean text. Use bullet points or short paragraphs where needed.\n",
    "\n",
    "Start now.\n",
    "\"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        res = llm_call_with_retry_circuit(prompt)\n",
    "\n",
    "        messages.append(AIMessage(res.text))\n",
    "        state[\"messages\"] = messages\n",
    "    except Exception as e:\n",
    "        messages.append(AIMessage(f\"❌ Error: {e}\"))\n",
    "        state[\"messages\"] = messages\n",
    "\n",
    "    return interrupt(\"continue_chat\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MCP client setup (keep same as original)\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "import sys\n",
    "\n",
    "CAREER_PLAN_SERVER = os.path.abspath(\n",
    "    \"E:\\\\LinkedIn_AI_Career_Bot - Copy\\\\linkedin\\\\career_plan_mcp.py\"\n",
    ")\n",
    "\n",
    "def call_career_plan_mcp(profile_data, messages, system_prompt):\n",
    "    \"\"\"Async call to the career-plan MCP tool.\"\"\"\n",
    "    server_params = StdioServerParameters(\n",
    "        command=sys.executable,\n",
    "        args=[CAREER_PLAN_SERVER],\n",
    "    )\n",
    "\n",
    "    with stdio_client(server_params) as (read, write):\n",
    "        with ClientSession(read, write) as session:\n",
    "            session.initialize()\n",
    "            result = session.call_tool(\n",
    "                \"generate_career_plan\",\n",
    "                arguments={\n",
    "                    \"profile_data\": profile_data,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": system_prompt,\n",
    "                        }\n",
    "                    ] + [\n",
    "                        {\n",
    "                            \"role\": (\n",
    "                                \"user\" if isinstance(m, HumanMessage) else \"assistant\"\n",
    "                            ),\n",
    "                            \"content\": m.content,\n",
    "                        }\n",
    "                        for m in messages\n",
    "                    ],\n",
    "                },\n",
    "            )\n",
    "            return result.content[0].text\n",
    "\n",
    "\n",
    "def get_user_id_from_profile(profile: dict) -> str:\n",
    "    \"\"\"Extract user ID from profile\"\"\"\n",
    "    return profile.get(\"user_id\", \n",
    "           profile.get(\"email\", \n",
    "           profile.get(\"linkedin_url\", \n",
    "           f\"user_{hash(str(profile))}\")))\n",
    "\n",
    "\n",
    "def extract_latest_user_query(messages: list[BaseMessage]) -> str:\n",
    "    \"\"\"Extract the latest user query from messages\"\"\"\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            return msg.content.strip()\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# FIX 2: Enhanced career plan node with proper context preservation\n",
    "# agents.py - The New Procedural Career Plan Node\n",
    "\n",
    "def procedural_career_plan_node(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Career planning node with full, optimized LangMem procedural learning.\n",
    "    \"\"\"\n",
    "    if not LANGMEM_AVAILABLE:\n",
    "        return interrupt({\"messages\": [AIMessage(\"Memory system is unavailable. Cannot create a procedural plan.\")]})\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    profile_data = state.get(\"profile_data\", {})\n",
    "    user_query = extract_latest_user_query(messages)\n",
    "\n",
    "    if not user_query:\n",
    "        return interrupt({\"messages\": [AIMessage(\"Please provide your career goal to generate a plan.\")]})\n",
    "\n",
    "    user_namespace = f\"user_{hash(str(profile_data))}\" if profile_data else \"anonymous\"\n",
    "    memory_context = \"\"\n",
    "\n",
    "    # Step 1: SEARCH for relevant structured memories using the langmem tool\n",
    "    try:\n",
    "        search_results = search_memory_tool.invoke({\n",
    "            \"query\": user_query, \"namespace\": user_namespace, \"top_k\": 3\n",
    "        })\n",
    "        if search_results:\n",
    "            logging.info(f\"Found {len(search_results)} relevant memories.\")\n",
    "            memory_context = \"\\n\\nLEARNINGS FROM PAST SESSIONS:\\n\"\n",
    "            for mem in search_results:\n",
    "                content = mem.get('value', {}).get('content', {})\n",
    "                memory_context += f\"- For a goal like '{content.get('career_goal', 'N/A')}', a successful strategy was: '{content.get('success_strategies', 'N/A')}'.\\n\"\n",
    "                memory_context += f\"  - A common obstacle to watch for is: '{content.get('common_obstacles', 'N/A')}'.\\n\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Memory search failed: {e}\")\n",
    "\n",
    "    # Step 2: BUILD the base prompt with augmented memory context\n",
    "    base_prompt = f\"\"\"\n",
    "You are an expert AI career coach. Create a personalized and actionable career plan.\n",
    "\n",
    "USER PROFILE: {json.dumps(profile_data, indent=2)}\n",
    "LATEST REQUEST: {user_query}\n",
    "{memory_context}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Create a comprehensive career plan based on the user's profile and request.\n",
    "- If learnings from past sessions are available, incorporate those successful strategies.\n",
    "- Provide concrete steps, realistic timelines, and suggest key resources.\n",
    "\"\"\"\n",
    "\n",
    "    # Step 3: OPTIMIZE the prompt using the langmem tool\n",
    "    final_prompt = base_prompt\n",
    "    try:\n",
    "        examples = [{\"input\": messages[i].content, \"output\": messages[i+1].content} for i in range(0, len(messages)-1, 2)]\n",
    "        if examples:\n",
    "            opt_result = prompt_optimizer.invoke({\n",
    "                \"prompt\": base_prompt, \"examples\": examples[-2:],\n",
    "                \"feedback\": \"Make the career plan more actionable and personalized.\"\n",
    "            })\n",
    "            final_prompt = opt_result.get(\"optimized_prompt\", base_prompt)\n",
    "            logging.info(\"Prompt optimized for clarity and actionability.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Prompt optimization failed: {e}\")\n",
    "\n",
    "    # Step 4: GENERATE the career plan using your MCP\n",
    "    try:\n",
    "        plan_output = call_career_plan_mcp(profile_data, messages, final_prompt)\n",
    "    except Exception as e:\n",
    "        plan_output = f\"Error generating career plan: {e}\"\n",
    "        logging.error(f\"Career plan generation failed: {e}\")\n",
    "\n",
    "    # Step 5: STORE the interaction. The memory manager will automatically extract and save structured insights.\n",
    "    if \"Error\" not in plan_output:\n",
    "        try:\n",
    "            conversation_to_learn_from = [HumanMessage(content=user_query), AIMessage(content=plan_output)]\n",
    "            memory_store_manager.invoke(\n",
    "                {\"messages\": conversation_to_learn_from, \"namespace\": user_namespace}\n",
    "            )\n",
    "            logging.info(\"Interaction stored and processed by the memory manager.\")\n",
    "            plan_output += \"\\n\\n*💾 Insights from this session have been saved to improve future advice.*\"\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to store procedural memories: {e}\")\n",
    "\n",
    "    return interrupt({\"messages\": [AIMessage(content=plan_output)]})\n",
    "\n",
    "\n",
    "# agents.py - Utility function using the manage_memory_tool\n",
    "\n",
    "async def clear_user_memories(profile_data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Clears all procedural memories for a given user profile using the manage_memory_tool.\n",
    "    \"\"\"\n",
    "    if not LANGMEM_AVAILABLE or not profile_data:\n",
    "        return {\"error\": \"Memory management not available or profile not loaded.\"}\n",
    "    \n",
    "    try:\n",
    "        user_namespace = f\"user_{hash(str(profile_data))}\"\n",
    "        result = await manage_memory_tool.ainvoke({\n",
    "            \"action\": \"clear\",\n",
    "            \"namespace\": user_namespace\n",
    "        })\n",
    "        logging.info(f\"Cleared all memories for namespace: {user_namespace}\")\n",
    "        return {\"success\": True, \"message\": f\"All memories for the current profile have been cleared.\"}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to clear memories: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Don't forget to update your __all__ export list at the bottom of the file\n",
    "# to include this new function if you want to import it elsewhere.\n",
    "# __all__ = [..., \"clear_user_memories\"]\n",
    "\n",
    "\n",
    "def build_graph():\n",
    "    \"\"\"Build the graph with all fixes applied\"\"\"\n",
    "    builder = StateGraph(AgentState)\n",
    "    \n",
    "    # Add all nodes\n",
    "    builder.add_node(\"linkedin_scraper\", linkedin_scraper_node)\n",
    "    builder.add_node(\"career_qa_router\", career_qa_router)\n",
    "    builder.add_node(\"analyze_profile\", analyze_profile_node)\n",
    "    builder.add_node(\"job_fit_agent\", job_fit_agent_node)\n",
    "    builder.add_node(\"enhance_profile\", enhance_profile_node)\n",
    "    builder.add_node(\"general_qa_node\", general_qa_node)\n",
    "    builder.add_node(\"career_plan\", procedural_career_plan_node)\n",
    "    \n",
    "    # FIX 3: Web search nodes\n",
    "    builder.add_node(\"websearch_mcp\", websearch_mcp_node)\n",
    "    builder.add_node(\"enrich_websearch\", enrich_websearch_node)\n",
    "    builder.add_node(\"store_websearch\", store_websearch_node)\n",
    "    \n",
    "    # Define entry point\n",
    "    builder.set_entry_point(\"linkedin_scraper\")\n",
    "    \n",
    "    # FIX 1: LinkedIn scraper goes to router (not both router and career_plan)\n",
    "    builder.add_edge(\"linkedin_scraper\", \"career_qa_router\")\n",
    "    \n",
    "    # Router connections\n",
    "    builder.add_edge(\"career_qa_router\", \"analyze_profile\")\n",
    "    builder.add_edge(\"career_qa_router\", \"job_fit_agent\")\n",
    "    builder.add_edge(\"career_qa_router\", \"enhance_profile\")\n",
    "    builder.add_edge(\"career_qa_router\", \"general_qa_node\")\n",
    "    builder.add_edge(\"career_qa_router\", \"career_plan\")\n",
    "    \n",
    "    \n",
    "    # FIX 3: Web search flow: search -> enrich -> store -> career_plan\n",
    "    builder.add_edge(\"career_plan\", \"store_websearch\")\n",
    "    builder.add_edge(\"career_plan\", \"enrich_websearch\")\n",
    "    builder.add_edge(\"career_plan\", \"websearch_mcp\")\n",
    "    builder.add_edge(\"websearch_mcp\", \"enrich_websearch\")\n",
    "    builder.add_edge(\"enrich_websearch\", \"store_websearch\")\n",
    "    builder.add_edge(\"store_websearch\", \"career_plan\")\n",
    "    \n",
    "    # All task nodes loop back to router for continued conversation\n",
    "    for task in [\"analyze_profile\", \"job_fit_agent\", \"enhance_profile\", \"general_qa_node\"]:\n",
    "        builder.add_edge(task, \"career_qa_router\")\n",
    "\n",
    "    return builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "\n",
    "# Create the enhanced graph\n",
    "graph = build_graph()\n",
    "\n",
    "\n",
    "def test_thread_based_learning():\n",
    "    \"\"\"Test the thread-based procedural learning system\"\"\"\n",
    "    print(\"=== TESTING THREAD-BASED PROCEDURAL LEARNING ===\")\n",
    "    \n",
    "    # Test profile data\n",
    "    test_profile = {\n",
    "        \"headline\": \"Software Engineer\",\n",
    "        \"skills\": [\"Python\", \"React\", \"AWS\"],\n",
    "        \"experience\": \"3 years\",\n",
    "        \"user_id\": \"test_user_123\"\n",
    "    }\n",
    "    \n",
    "    # Test storing thread data\n",
    "    # success = thread_procedural_memory.store_thread_data(\n",
    "    #     thread_id=\"test_thread_1\",\n",
    "    #     profile_data=test_profile,\n",
    "    #     user_query=\"I want to transition to data science\",\n",
    "    #     ai_response=\"Here's a comprehensive data science transition plan: 1. Learn Python for data science...\",\n",
    "    #     user_id=\"test_user_123\"\n",
    "    # )\n",
    "    \n",
    "    # print(f\"Store test: {'✅ PASSED' if success else '❌ FAILED'}\")\n",
    "    \n",
    "    # Test retrieval\n",
    "    # similar_threads = thread_procedural_memory.get_similar_threads(\n",
    "    #     query=\"data science career transition\",\n",
    "    #     user_id=\"test_user_123\"\n",
    "    # )\n",
    "    \n",
    "    # print(f\"Retrieval test: {'✅ PASSED' if similar_threads else '❌ FAILED'}\")\n",
    "    \n",
    "    # Debug the test thread\n",
    "    # thread_procedural_memory.debug_thread(\"test_thread_1\")\n",
    "    \n",
    "    print(\"=== TEST COMPLETE ===\")\n",
    "\n",
    "\n",
    "_all_ = [\"graph\", \"memory\", \"thread_procedural_memory\", \"test_thread_based_learning\"]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Testing Enhanced Thread-Based Procedural Learning ---\")\n",
    "    test_thread_based_learning()\n",
    "    \n",
    "    print(\"\\n--- Testing Graph with All Fixes ---\")\n",
    "    \n",
    "    # Test the complete workflow\n",
    "    test_state = {\n",
    "        \"messages\": [HumanMessage(content=\"I want to transition from software engineering to AI/ML\")],\n",
    "        \"profile_data\": {\n",
    "            \"headline\": \"Senior Software Engineer\", \n",
    "            \"skills\": [\"Python\", \"JavaScript\", \"React\"],\n",
    "            \"experience\": \"5 years\",\n",
    "            \"user_id\": \"test_user_integration\"\n",
    "        },\n",
    "        \"linkedin_url\": \"https://linkedin.com/in/testuser\",\n",
    "        \"thread_id\": \"integration_test_thread\",\n",
    "        \"profile_scraped\": True  # Mark as already scraped\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        result = graph.invoke(\n",
    "            test_state,\n",
    "            config={\"configurable\": {\"thread_id\": \"integration_test_thread\"}}\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Graph execution successful\")\n",
    "        print(f\"Messages generated: {len(result.get('messages', []))}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Graph execution failed: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "660d3778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "    # Assuming 'graph' is your compiled LangGraph object\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa0b38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MongoDB persistence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:root:ThreadBasedProceduralMemory initialized successfully\n",
      "INFO:root:Profile already scraped in this session, skipping scraper\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING ENHANCED DUAL-SEGMENT GRAPH ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:LLM call failed on attempt 1: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "WARNING:root:LLM call failed on attempt 2: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 21\n",
      "}\n",
      "]\n",
      "WARNING:root:LLM call failed on attempt 3: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 18\n",
      "}\n",
      "]\n",
      "ERROR:root:Circuit opened after 3 consecutive failures.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Routing segment test successful\n",
      "Messages: 3\n",
      "✅ Career plan segment structure verified\n",
      "=== ENHANCED FUNCTIONALITY TEST COMPLETE ===\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import operator\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import traceback\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "import functools\n",
    "import logging\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "APIFY_TOKEN = os.getenv(\"APIFY_API_KEY\")\n",
    "\n",
    "# Set up basic logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Circuit breaker state\n",
    "circuit_open = False\n",
    "failure_count = 0\n",
    "failure_threshold = 3\n",
    "circuit_reset_time = 30\n",
    "last_failure_time = 0\n",
    "\n",
    "def llm_call_with_retry_circuit(prompt: str, max_retries=3, retry_delay=2):\n",
    "    \"\"\"Wrapper for model.generate_content with retry and circuit breaker\"\"\"\n",
    "    global circuit_open, failure_count, last_failure_time\n",
    "\n",
    "    if circuit_open:\n",
    "        if time.time() - last_failure_time < circuit_reset_time:\n",
    "            logging.warning(\"Circuit open. Skipping LLM call.\")\n",
    "            raise RuntimeError(\"Circuit open due to repeated failures\")\n",
    "        else:\n",
    "            logging.info(\"Resetting circuit breaker.\")\n",
    "            circuit_open = False\n",
    "            failure_count = 0\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            res = model.generate_content(prompt)\n",
    "            if hasattr(res, \"usage\"):\n",
    "                tokens = res.usage.get(\"total_tokens\", \"N/A\")\n",
    "                cost = tokens * 0.00001\n",
    "                logging.info(f\"LLM call successful | Tokens: {tokens} | Cost: ${cost:.6f}\")\n",
    "            failure_count = 0\n",
    "            return res\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"LLM call failed on attempt {attempt}: {e}\")\n",
    "            failure_count += 1\n",
    "            last_failure_time = time.time()\n",
    "            if failure_count >= failure_threshold:\n",
    "                circuit_open = True\n",
    "                logging.error(f\"Circuit opened after {failure_count} consecutive failures.\")\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                raise RuntimeError(f\"LLM call failed after {max_retries} attempts: {e}\")\n",
    "\n",
    "# MongoDB setup\n",
    "try:\n",
    "    from langgraph.checkpoint.mongodb import MongoDBSaver\n",
    "    mongo_url = os.getenv(\"MONGODB_URI\", \"mongodb://localhost:27017\")\n",
    "    client = MongoClient(mongo_url, serverSelectionTimeoutMS=2000)\n",
    "    client.admin.command(\"ping\")\n",
    "    db_name = \"career_bot\"\n",
    "    collection_name = \"checkpoints\"\n",
    "    db = client[\"career_bot\"]\n",
    "    collection = db[\"checkpoints\"]\n",
    "    if collection.count_documents({}) == 0:\n",
    "        collection.insert_one({\"_init\": True})\n",
    "        print(f\"Created DB '{db_name}' and collection '{collection_name}'\")\n",
    "    memory = MongoDBSaver(client=client, db_name=\"career_bot\", collection_name=\"checkpoints\")\n",
    "    print(\"Using MongoDB persistence\")\n",
    "except Exception as e:\n",
    "    from langgraph.checkpoint.memory import MemorySaver\n",
    "    memory = MemorySaver()\n",
    "    tb = traceback.format_exc()\n",
    "    print(f\"Falling back to in-memory persistence: {e}\")\n",
    "\n",
    "import google.generativeai as genai\n",
    "from scraper_utils import scrape_and_clean_profile\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"models/gemini-1.5-flash\")\n",
    "\n",
    "# Enhanced State with separate segments\n",
    "class AgentState(TypedDict, total=False):\n",
    "    messages: Annotated[list[BaseMessage], operator.add]\n",
    "    profile_data: Annotated[dict, lambda _, x: x]\n",
    "    current_job_description: Annotated[Optional[str], lambda _, x: x]\n",
    "    linkedin_url: Annotated[Optional[str], lambda _, x: x]\n",
    "    thread_id: Annotated[Optional[str], lambda _, x: x]\n",
    "    websearch_results: Annotated[list, lambda _, x: x]\n",
    "    websearch_summary: Annotated[list, lambda _, x: x]\n",
    "    profile_scraped: Annotated[bool, lambda _, x: x]\n",
    "    # Segment tracking\n",
    "    current_segment: Annotated[str, lambda _, x: x]  # 'routing' or 'career_plan'\n",
    "    # Career plan specific states\n",
    "    career_plan_draft: Annotated[Optional[str], lambda _, x: x]\n",
    "    career_plan_review_notes: Annotated[Optional[str], lambda _, x: x]\n",
    "    career_plan_final: Annotated[Optional[str], lambda _, x: x]\n",
    "    career_plan_in_review: Annotated[bool, lambda _, x: x]\n",
    "\n",
    "# Web search functionality\n",
    "from apify_client import ApifyClient\n",
    "\n",
    "def websearch_mcp_node(state: AgentState) -> dict:\n",
    "    messages = state.get(\"messages\", [])\n",
    "    messages.append(AIMessage(\"🔍 Fetching web data...\"))\n",
    "\n",
    "    query = \"\"\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            query = msg.content.strip()\n",
    "            break\n",
    "\n",
    "    if not query:\n",
    "        messages.append(AIMessage(\"⚠ No query provided for web search.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return state\n",
    "\n",
    "    api_token = os.getenv(\"APIFY_API_KEY\")\n",
    "    if not api_token:\n",
    "        messages.append(AIMessage(\"❌ Apify API token not configured.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return state\n",
    "\n",
    "    client = ApifyClient(api_token)\n",
    "    actor_id = \"apify/google-search-scraper\"\n",
    "    input_data = {\n",
    "        \"queries\": [query], \n",
    "        \"maxPagesPerQuery\": 1,\n",
    "        \"resultsPerPage\": 5,\n",
    "        \"countryCode\": \"US\",\n",
    "        \"languageCode\": \"en\"\n",
    "    }\n",
    "\n",
    "    max_retries = 3\n",
    "    retry_delay = 2\n",
    "    results = []\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            logging.info(f\"Starting Apify web search for: {query}\")\n",
    "            run = client.actor(actor_id).call(run_input=input_data)\n",
    "            dataset_items = client.dataset(run[\"defaultDatasetId\"]).list_items().items\n",
    "            logging.info(f\"Retrieved {len(dataset_items)} items from Apify\")\n",
    "            \n",
    "            for item in dataset_items:\n",
    "                search_results = item.get(\"searchResults\", [])\n",
    "                for result in search_results:\n",
    "                    results.append({\n",
    "                        \"title\": result.get(\"title\", \"\"),\n",
    "                        \"link\": result.get(\"url\", \"\"),\n",
    "                        \"snippet\": result.get(\"description\", \"\")\n",
    "                    })\n",
    "\n",
    "            if results:\n",
    "                messages.append(\n",
    "                    AIMessage(f\"🔍 WebSearch results fetched via Apify ({len(results)} results)\")\n",
    "                )\n",
    "                logging.info(f\"Successfully found {len(results)} web search results\")\n",
    "            else:\n",
    "                messages.append(AIMessage(\"⚠ No search results found.\"))\n",
    "            break\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Apify search attempt {attempt} failed: {e}\")\n",
    "            if attempt < max_retries:\n",
    "                messages.append(AIMessage(f\"⚠ Apify attempt {attempt} failed. Retrying...\"))\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                messages.append(AIMessage(f\"❌ Apify WebSearch failed after {max_retries} attempts: {e}\"))\n",
    "\n",
    "    state[\"messages\"] = messages\n",
    "    state[\"websearch_results\"] = results\n",
    "    return state\n",
    "\n",
    "def enrich_websearch_node(state):\n",
    "    messages = state.get(\"messages\", [])\n",
    "    results = state.get(\"websearch_results\", [])\n",
    "    \n",
    "    if not results:\n",
    "        messages.append(AIMessage(\"⚠ No search results to enrich.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return state\n",
    "\n",
    "    summary = []\n",
    "    for r in results:\n",
    "        content = r.get(\"snippet\") or r.get(\"content\") or r.get(\"description\", \"\")\n",
    "        \n",
    "        if not content and r.get(\"link\"):\n",
    "            try:\n",
    "                import requests\n",
    "                response = requests.get(r[\"link\"], timeout=10, headers={\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "                })\n",
    "                content = response.text[:2000]\n",
    "            except Exception as e:\n",
    "                content = f\"Could not fetch content: {e}\"\n",
    "\n",
    "        try:\n",
    "            if content and len(content) > 50:\n",
    "                summary_prompt = f\"Summarize the key points for career planning from this content:\\n\\n{content[:1500]}\"\n",
    "                res = llm_call_with_retry_circuit(summary_prompt)\n",
    "                summary_text = res.text\n",
    "            else:\n",
    "                summary_text = content or \"No content available\"\n",
    "                \n",
    "            summary.append({\n",
    "                \"title\": r[\"title\"], \n",
    "                \"link\": r[\"link\"], \n",
    "                \"summary\": summary_text[:500]\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error enriching search result: {e}\")\n",
    "            summary.append({\n",
    "                \"title\": r[\"title\"], \n",
    "                \"link\": r[\"link\"], \n",
    "                \"summary\": f\"❌ Could not summarize: {e}\"\n",
    "            })\n",
    "\n",
    "    messages.append(AIMessage(f\"✅ Search results enriched with AI summaries ({len(summary)} results).\"))\n",
    "    state[\"messages\"] = messages\n",
    "    state[\"websearch_summary\"] = summary\n",
    "    return state\n",
    "\n",
    "def store_websearch_node(state: AgentState) -> dict:\n",
    "    try:\n",
    "        client = MongoClient(os.getenv(\"MONGODB_URI\", \"mongodb://localhost:27017\"))\n",
    "        db = client[\"career_bot\"]\n",
    "        collection = db[\"websearch\"]\n",
    "\n",
    "        results = state.get(\"websearch_summary\", [])\n",
    "        if results:\n",
    "            import datetime\n",
    "            for result in results:\n",
    "                result[\"timestamp\"] = datetime.datetime.utcnow().isoformat()\n",
    "                result[\"thread_id\"] = state.get(\"thread_id\", \"unknown\")\n",
    "            \n",
    "            collection.insert_many(results)\n",
    "            state[\"messages\"].append(AIMessage(f\"💾 Stored {len(results)} search results in DB.\"))\n",
    "        else:\n",
    "            state[\"messages\"].append(AIMessage(\"⚠ Nothing to store.\"))\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error storing websearch results: {e}\")\n",
    "        state[\"messages\"].append(AIMessage(\"⚠ Failed to store search results.\"))\n",
    "\n",
    "    return state\n",
    "\n",
    "# SEGMENT 1: ROUTING NODES\n",
    "\n",
    "def linkedin_scraper_node(state: dict) -> dict:\n",
    "    \"\"\"Scrapes LinkedIn profile URL only if not already scraped\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    thread_id = state.get(\"thread_id\", \"default_thread\")\n",
    "    profile_scraped = state.get(\"profile_scraped\", False)\n",
    "    existing_profile = state.get(\"profile_data\")\n",
    "\n",
    "    if profile_scraped and existing_profile:\n",
    "        logging.info(\"Profile already scraped in this session, skipping scraper\")\n",
    "        state[\"current_segment\"] = \"routing\"\n",
    "        return Command(goto=[\"career_qa_router\"], update=state)\n",
    "\n",
    "    linkedin_url = state.get(\"linkedin_url\", \"\").strip()\n",
    "\n",
    "    if not linkedin_url:\n",
    "        messages.append(AIMessage(\"Please provide a LinkedIn profile URL to begin.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        state[\"current_segment\"] = \"routing\"\n",
    "        return interrupt(\"routing_continue\")\n",
    "\n",
    "    messages.append(AIMessage(\"Scraping your LinkedIn profile...\"))\n",
    "\n",
    "    try:\n",
    "        scraped_profile = scrape_and_clean_profile(\n",
    "            linkedin_url=linkedin_url, api_token=os.getenv(\"APIFY_API_KEY\")\n",
    "        )\n",
    "\n",
    "        if not scraped_profile:\n",
    "            messages.append(AIMessage(\"Failed to extract profile. Try again.\"))\n",
    "            state[\"messages\"] = messages\n",
    "            return interrupt(\"routing_continue\")\n",
    "\n",
    "        messages.append(AIMessage(\"Profile successfully scraped!\"))\n",
    "        state[\"profile_data\"] = scraped_profile\n",
    "        state[\"profile_scraped\"] = True\n",
    "        state[\"messages\"] = messages\n",
    "        state[\"thread_id\"] = thread_id\n",
    "        state[\"current_segment\"] = \"routing\"\n",
    "\n",
    "    except Exception as e:\n",
    "        messages.append(AIMessage(f\"Error scraping LinkedIn profile: {e}\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"routing_continue\")\n",
    "\n",
    "    return Command(goto=[\"career_qa_router\"], update=state)\n",
    "\n",
    "def career_qa_router(state: AgentState) -> Command:\n",
    "    \"\"\"Enhanced router using only LLM-based routing, no keyword matching\"\"\"\n",
    "    profile = state.get(\"profile_data\", {})\n",
    "    jd = state.get(\"current_job_description\", \"\")\n",
    "    messages = state.get(\"messages\", [])\n",
    "    question = \"\"\n",
    "\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            question = msg.content.strip()\n",
    "            break\n",
    "\n",
    "    if question.lower() in {\"quit\", \"exit\", \"stop\"}:\n",
    "        messages.append(AIMessage(\"Okay, ending the routing conversation.\"))\n",
    "        return Command(goto=END, update={\"messages\": messages})\n",
    "\n",
    "    if \"job description:\" in question.lower():\n",
    "        messages.append(AIMessage(\"Got your new job description.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        state[\"current_job_description\"] = question\n",
    "        return interrupt(\"routing_continue\")\n",
    "\n",
    "    history = \"\\n\".join(\n",
    "        f\"Human: {m.content}\" if isinstance(m, HumanMessage) else f\"AI: {m.content}\"\n",
    "        for m in messages[-5:]\n",
    "    )\n",
    "\n",
    "    # Enhanced routing prompt with detailed instructions - NO KEYWORD MATCHING\n",
    "    routing_prompt = f\"\"\"\n",
    "You are an intelligent routing agent for a career assistance system. Your job is to analyze the user's question and determine which specialized module should handle it.\n",
    "\n",
    "CONVERSATION HISTORY:\n",
    "{history}\n",
    "\n",
    "USER'S CURRENT QUESTION:\n",
    "{question}\n",
    "\n",
    "AVAILABLE MODULES:\n",
    "1. analyze_profile - For LinkedIn/resume/profile reviews, feedback, strengths/weaknesses analysis, profile audits\n",
    "2. job_fit_agent - For matching profiles against job descriptions, eligibility assessment, scoring against roles\n",
    "3. enhance_profile - For rewriting/improving profile sections, optimization, content enhancement\n",
    "4. general_qa - For general career questions, advice, industry insights, job search strategy\n",
    "\n",
    "ROUTING RULES:\n",
    "- Analyze the INTENT and CONTEXT of the user's question, not just keywords\n",
    "- Consider what the user is trying to accomplish\n",
    "- Look at the conversation history to understand the flow\n",
    "- If a job description was recently provided, consider if they want to use it\n",
    "\n",
    "Based on the user's question and intent, which module should handle this?\n",
    "\n",
    "Respond with ONLY ONE of these exact options:\n",
    "analyze_profile\n",
    "job_fit_agent  \n",
    "enhance_profile\n",
    "general_qa\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        result = llm_call_with_retry_circuit(routing_prompt)\n",
    "        decision = result.text.strip().lower()\n",
    "\n",
    "        valid_routes = [\"analyze_profile\", \"job_fit_agent\", \"enhance_profile\", \"general_qa\"]\n",
    "        \n",
    "        if decision in valid_routes:\n",
    "            state[\"messages\"] = messages\n",
    "            target_node = decision if decision != \"general_qa\" else \"general_qa_node\"\n",
    "            return Command(goto=target_node, update=state)\n",
    "        else:\n",
    "            messages.append(AIMessage(\"⚠ I didn't understand your request. Could you please rephrase it?\"))\n",
    "            state[\"messages\"] = messages\n",
    "            return interrupt(\"routing_continue\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        messages.append(AIMessage(f\"⚠ Routing error: {e}\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"routing_continue\")\n",
    "\n",
    "def analyze_profile_node(state: AgentState) -> dict:\n",
    "    \"\"\"Profile analysis with interrupt/resume for routing segment\"\"\"\n",
    "    profile = state.get(\"profile_data\")\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    if not profile:\n",
    "        messages.append(AIMessage(\"⚠ No profile data found to analyze.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"routing_continue\")\n",
    "\n",
    "    profile_text = \"\\n\".join(f\"{k}: {v}\" for k, v in profile.items())\n",
    "    history = \"\\n\".join(\n",
    "        f\"Human: {m.content}\" if isinstance(m, HumanMessage) else f\"AI: {m.content}\"\n",
    "        for m in messages[-5:]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "{history}\n",
    "\n",
    "You are a highly experienced career coach and tech recruiter. Provide a detailed LinkedIn profile analysis.\n",
    "\n",
    "PROFILE DATA:\n",
    "{profile_text}\n",
    "\n",
    "Provide a comprehensive analysis with:\n",
    "1. **Strengths** - 3-5 key strengths across the profile\n",
    "2. **Weaknesses** - 3-5 areas needing improvement  \n",
    "3. **Section-by-Section Evaluation** - Rate each section and provide specific suggestions\n",
    "4. **Top 3 Actionable Improvements** - Specific, implementable changes\n",
    "\n",
    "Keep feedback constructive, specific, and actionable.\n",
    "\"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        res = llm_call_with_retry_circuit(prompt)\n",
    "        messages.append(AIMessage(res.text))\n",
    "        state[\"messages\"] = messages\n",
    "    except Exception as e:\n",
    "        messages.append(AIMessage(f\"❌ Error: {e}\"))\n",
    "        state[\"messages\"] = messages\n",
    "\n",
    "    return interrupt(\"routing_continue\")\n",
    "\n",
    "def job_fit_agent_node(state: AgentState) -> dict:\n",
    "    \"\"\"Job fit analysis with interrupt/resume for routing segment\"\"\"\n",
    "    profile = state.get(\"profile_data\")\n",
    "    jd = state.get(\"current_job_description\", \"\")\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    if not profile or not jd:\n",
    "        messages.append(AIMessage(\"⚠ Missing profile or job description for analysis.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"routing_continue\")\n",
    "\n",
    "    profile_text = \"\\n\".join(f\"{k}: {v}\" for k, v in profile.items())\n",
    "    history = \"\\n\".join(\n",
    "        f\"Human: {m.content}\" if isinstance(m, HumanMessage) else f\"AI: {m.content}\"\n",
    "        for m in messages[-5:]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "{history}\n",
    "\n",
    "You are an AI Job Fit Evaluator. Analyze how well this candidate's profile matches the job description.\n",
    "\n",
    "JOB DESCRIPTION:\n",
    "{jd}\n",
    "\n",
    "CANDIDATE PROFILE:\n",
    "{profile_text}\n",
    "\n",
    "Provide:\n",
    "1. **Job Match Score**: X/100 with detailed reasoning\n",
    "2. **Strengths**: 3-5 profile strengths that align with the job\n",
    "3. **Weaknesses**: 3-5 areas where the profile doesn't match or lacks requirements\n",
    "4. **Improvements**: Specific suggestions to increase match score\n",
    "5. **Verdict**: Clear recommendation on application readiness\n",
    "\n",
    "Be honest and thorough in your evaluation.\n",
    "\"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        res = llm_call_with_retry_circuit(prompt)\n",
    "        messages.append(AIMessage(res.text))\n",
    "        state[\"messages\"] = messages\n",
    "    except Exception as e:\n",
    "        messages.append(AIMessage(f\"❌ Error: {e}\"))\n",
    "        state[\"messages\"] = messages\n",
    "\n",
    "    return interrupt(\"routing_continue\")\n",
    "\n",
    "def enhance_profile_node(state: AgentState) -> dict:\n",
    "    \"\"\"Profile enhancement with interrupt/resume for routing segment\"\"\"\n",
    "    profile = state.get(\"profile_data\")\n",
    "    jd = state.get(\"current_job_description\", \"\")\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    if not profile:\n",
    "        messages.append(AIMessage(\"⚠ No profile found to enhance.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"routing_continue\")\n",
    "\n",
    "    profile_text = \"\\n\".join(f\"{k}: {v}\" for k, v in profile.items())\n",
    "    history = \"\\n\".join(\n",
    "        f\"Human: {m.content}\" if isinstance(m, HumanMessage) else f\"AI: {m.content}\"\n",
    "        for m in messages[-5:]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "{history}\n",
    "\n",
    "You are a LinkedIn Profile Optimization expert. Rewrite and improve the user's profile sections.\n",
    "\n",
    "CURRENT PROFILE:\n",
    "{profile_text}\n",
    "\n",
    "JOB DESCRIPTION (if targeting specific role):\n",
    "{jd}\n",
    "\n",
    "Instructions:\n",
    "1. Identify weak sections and rewrite them with stronger, more professional language\n",
    "2. Preserve all factual details - do NOT add imaginary experiences\n",
    "3. Use impactful verbs, metrics, and proof of value\n",
    "4. Align with job description if provided, or general best practices\n",
    "5. Focus on the sections the user specifically requested, or all if general request\n",
    "\n",
    "Provide the improved sections in clean, professional format.\n",
    "\"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        res = llm_call_with_retry_circuit(prompt)\n",
    "        messages.append(AIMessage(res.text))\n",
    "        state[\"messages\"] = messages\n",
    "    except Exception as e:\n",
    "        messages.append(AIMessage(f\"❌ Error: {e}\"))\n",
    "        state[\"messages\"] = messages\n",
    "\n",
    "    return interrupt(\"routing_continue\")\n",
    "\n",
    "def general_qa_node(state: AgentState) -> dict:\n",
    "    \"\"\"General career Q&A with interrupt/resume for routing segment\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    question = \"\"\n",
    "    \n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            question = msg.content.strip()\n",
    "            break\n",
    "\n",
    "    history = \"\\n\".join(\n",
    "        f\"Human: {m.content}\" if isinstance(m, HumanMessage) else f\"AI: {m.content}\"\n",
    "        for m in messages[-5:]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful career guidance assistant providing advice on career-related questions.\n",
    "\n",
    "CONVERSATION HISTORY:\n",
    "{history}\n",
    "\n",
    "PROFILE CONTEXT: {state.get(\"profile_data\", {}).get(\"headline\", \"N/A\")}\n",
    "JOB DESCRIPTION: {state.get(\"current_job_description\", \"N/A\")}\n",
    "\n",
    "USER QUESTION: {question}\n",
    "\n",
    "Provide clear, actionable career advice. Focus on practical guidance the user can implement.\n",
    "\"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        res = llm_call_with_retry_circuit(prompt)\n",
    "        messages.append(AIMessage(res.text))\n",
    "        state[\"messages\"] = messages\n",
    "    except Exception as e:\n",
    "        messages.append(AIMessage(f\"❌ Error: {e}\"))\n",
    "        state[\"messages\"] = messages\n",
    "\n",
    "    return interrupt(\"routing_continue\")\n",
    "\n",
    "# SEGMENT 2: CAREER PLAN NODES\n",
    "\n",
    "def career_plan_entry_node(state: AgentState) -> dict:\n",
    "    \"\"\"Entry point for career plan segment\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    thread_id = state.get(\"thread_id\", \"default_thread\")\n",
    "    profile = state.get(\"profile_data\", {})\n",
    "    \n",
    "    if not profile:\n",
    "        messages.append(AIMessage(\"⚠ No profile data available for career planning.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"career_plan_continue\")\n",
    "\n",
    "    # Extract career plan request\n",
    "    career_request = \"\"\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            career_request = msg.content.strip()\n",
    "            break\n",
    "\n",
    "    if not career_request:\n",
    "        messages.append(AIMessage(\"Please provide a career goal or request for your plan.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"career_plan_continue\")\n",
    "\n",
    "    state[\"current_segment\"] = \"career_plan\"\n",
    "    state[\"career_plan_in_review\"] = False\n",
    "\n",
    "    # Check if web search is needed based on LLM analysis\n",
    "    search_analysis_prompt = f\"\"\"\n",
    "Analyze this career planning request to determine if web search for current resources is needed:\n",
    "\n",
    "REQUEST: {career_request}\n",
    "PROFILE: {profile.get('headline', 'Unknown')}\n",
    "\n",
    "Should we search for current courses, certifications, training resources, or market information to enhance this career plan?\n",
    "\n",
    "Respond with only: YES or NO\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        search_decision = llm_call_with_retry_circuit(search_analysis_prompt)\n",
    "        needs_search = \"yes\" in search_decision.text.lower()\n",
    "        \n",
    "        if needs_search:\n",
    "            logging.info(\"Career plan requires web search\")\n",
    "            return Command(goto=[\"websearch_mcp\"], update=state)\n",
    "        else:\n",
    "            return Command(goto=[\"career_plan_generator\"], update=state)\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Search decision failed: {e}\")\n",
    "        return Command(goto=[\"career_plan_generator\"], update=state)\n",
    "\n",
    "def career_plan_generator_node(state: AgentState) -> dict:\n",
    "    \"\"\"Generate career plan with interrupt for review\"\"\"\n",
    "    profile = state.get(\"profile_data\", {})\n",
    "    messages = state.get(\"messages\", [])\n",
    "    websearch_summary = state.get(\"websearch_summary\", [])\n",
    "    \n",
    "    # Extract career request\n",
    "    career_request = \"\"\n",
    "    conversation_context = \"\"\n",
    "    \n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            career_request = msg.content.strip()\n",
    "            break\n",
    "    \n",
    "    # Build conversation context\n",
    "    conversation_context = \"\\n\".join([\n",
    "        f\"{'User' if isinstance(msg, HumanMessage) else 'Assistant'}: {msg.content[:200]}...\"\n",
    "        for msg in messages[-6:]\n",
    "    ])\n",
    "\n",
    "    # Build comprehensive prompt\n",
    "    base_prompt = f\"\"\"\n",
    "You are an expert AI career coach with 10+ years of experience. Create a detailed, actionable career plan.\n",
    "\n",
    "CAREER REQUEST: {career_request}\n",
    "\n",
    "CONVERSATION CONTEXT:\n",
    "{conversation_context}\n",
    "\n",
    "PROFILE SUMMARY:\n",
    "- Headline: {profile.get('headline', 'Unknown')}\n",
    "- Skills: {profile.get('skills', 'Not specified')}\n",
    "- Experience Level: {profile.get('experience', 'Not specified')}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Add web search results if available\n",
    "    if websearch_summary:\n",
    "        web_context = \"\\nCURRENT RESOURCES FOUND:\\n\"\n",
    "        for i, result in enumerate(websearch_summary[:3], 1):\n",
    "            web_context += f\"{i}. {result.get('title', 'Unknown')}\\n\"\n",
    "            web_context += f\"   Summary: {result.get('summary', '')[:200]}...\\n\"\n",
    "            web_context += f\"   Link: {result.get('link', '')}\\n\\n\"\n",
    "        \n",
    "        base_prompt += web_context\n",
    "        base_prompt += \"\\nIMPORTANT: Include specific courses and resources from the web research in your plan.\\n\"\n",
    "\n",
    "    base_prompt += \"\"\"\n",
    "Create a comprehensive career plan that includes:\n",
    "1. **Goal Analysis** - Understand their specific objective\n",
    "2. **Current State Assessment** - Based on their profile\n",
    "3. **Action Plan** - Step-by-step roadmap with timelines\n",
    "4. **Skill Development** - Specific courses, certifications, resources\n",
    "5. **Networking & Experience** - Practical steps for growth\n",
    "6. **Success Metrics** - How to measure progress\n",
    "\n",
    "Make it specific, actionable, and personalized to their profile and request.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Call career plan MCP service\n",
    "        from career_plan_mcp import mcp\n",
    "        \n",
    "        plan_result = asyncio.run(call_career_plan_mcp(profile, messages, base_prompt))\n",
    "        plan_output = plan_result if isinstance(plan_result, str) else str(plan_result)\n",
    "        \n",
    "        messages.append(AIMessage(plan_output))\n",
    "        state[\"messages\"] = messages\n",
    "        state[\"career_plan_draft\"] = plan_output\n",
    "        state[\"career_plan_in_review\"] = True\n",
    "        \n",
    "        # Store for procedural learning\n",
    "        try:\n",
    "            thread_procedural_memory.store_thread_data(\n",
    "                thread_id=state.get(\"thread_id\", \"default\"),\n",
    "                profile_data=profile,\n",
    "                user_query=career_request,\n",
    "                ai_response=plan_output,\n",
    "                user_id=profile.get(\"user_id\", \"unknown\")\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to store procedural data: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        plan_output = f\"Error generating career plan: {e}\"\n",
    "        messages.append(AIMessage(plan_output))\n",
    "        state[\"messages\"] = messages\n",
    "        logging.error(f\"Career plan generation failed: {e}\")\n",
    "\n",
    "    # Interrupt for review\n",
    "    return interrupt(\"career_plan_review\")\n",
    "\n",
    "def career_plan_review_node(state: AgentState) -> dict:\n",
    "    \"\"\"Process review feedback and update career plan\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    profile = state.get(\"profile_data\", {})\n",
    "    draft_plan = state.get(\"career_plan_draft\", \"\")\n",
    "    \n",
    "    if not state.get(\"career_plan_in_review\"):\n",
    "        messages.append(AIMessage(\"No career plan currently in review.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"career_plan_continue\")\n",
    "\n",
    "    # Extract review feedback\n",
    "    review_feedback = \"\"\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            review_feedback = msg.content.strip()\n",
    "            break\n",
    "\n",
    "    if not review_feedback:\n",
    "        messages.append(AIMessage(\"Please provide your review feedback for the career plan.\"))\n",
    "        state[\"messages\"] = messages\n",
    "        return interrupt(\"career_plan_review\")\n",
    "\n",
    "    # Process the review and update plan\n",
    "    review_prompt = f\"\"\"\n",
    "You are an expert career coach. A user has reviewed their career plan and provided feedback. \n",
    "Update the plan based on their specific feedback while maintaining the original context and goals.\n",
    "\n",
    "ORIGINAL CAREER PLAN:\n",
    "{draft_plan}\n",
    "\n",
    "USER FEEDBACK:\n",
    "{review_feedback}\n",
    "\n",
    "USER PROFILE CONTEXT:\n",
    "- Headline: {profile.get('headline', 'Unknown')}\n",
    "- Skills: {profile.get('skills', 'Not specified')}\n",
    "\n",
    "Instructions:\n",
    "1. Carefully analyze what changes the user is requesting\n",
    "2. Apply those changes while maintaining the overall structure and quality\n",
    "3. Keep all the good elements from the original plan\n",
    "4. Make sure the revised plan still flows logically and is actionable\n",
    "5. If they want timeline changes, adjust accordingly\n",
    "6. If they want focus changes, rebalance the content\n",
    "\n",
    "Provide the complete updated career plan:\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        result = llm_call_with_retry_circuit(review_prompt)\n",
    "        updated_plan = result.text\n",
    "        \n",
    "        messages.append(AIMessage(\"✅ Career plan updated based on your feedback:\"))\n",
    "        messages.append(AIMessage(updated_plan))\n",
    "        \n",
    "        state[\"messages\"] = messages\n",
    "        state[\"career_plan_final\"] = updated_plan\n",
    "        state[\"career_plan_in_review\"] = False\n",
    "        \n",
    "    except Exception as e:\n",
    "        messages.append(AIMessage(f\"❌ Error updating plan: {e}\"))\n",
    "        state[\"messages\"] = messages\n",
    "\n",
    "    return interrupt(\"career_plan_continue\")\n",
    "\n",
    "# Import remaining utilities\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "import sys\n",
    "\n",
    "CAREER_PLAN_SERVER = os.path.abspath(\"career_plan_mcp.py\")\n",
    "\n",
    "async def call_career_plan_mcp(profile_data, messages, system_prompt):\n",
    "    \"\"\"Async call to the career-plan MCP tool\"\"\"\n",
    "    server_params = StdioServerParameters(\n",
    "        command=sys.executable,\n",
    "        args=[CAREER_PLAN_SERVER],\n",
    "    )\n",
    "\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            result = await session.call_tool(\n",
    "                \"generate_career_plan\",\n",
    "                arguments={\n",
    "                    \"profile_data\": profile_data,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": system_prompt}\n",
    "                    ] + [\n",
    "                        {\n",
    "                            \"role\": \"user\" if isinstance(m, HumanMessage) else \"assistant\",\n",
    "                            \"content\": m.content,\n",
    "                        }\n",
    "                        for m in messages\n",
    "                    ],\n",
    "                },\n",
    "            )\n",
    "            return result.content[0].text\n",
    "\n",
    "# ThreadBasedProceduralMemory class (keeping existing implementation)\n",
    "class ThreadBasedProceduralMemory:\n",
    "    \"\"\"Enhanced procedural learning with thread-based storage in MongoDB\"\"\"\n",
    "    \n",
    "    def __init__(self, mongo_url: str = None, db_name: str = \"career_bot\"):\n",
    "        self.mongo_url = mongo_url or os.getenv(\"MONGODB_URI\", \"mongodb://localhost:27017\")\n",
    "        self.db_name = db_name\n",
    "        self.collection_name = \"procedural_threads\"\n",
    "        self._client = None\n",
    "        self._collection = None\n",
    "        self._initialize_connection()\n",
    "    \n",
    "    def _initialize_connection(self):\n",
    "        \"\"\"Initialize MongoDB connection\"\"\"\n",
    "        try:\n",
    "            self._client = MongoClient(self.mongo_url, serverSelectionTimeoutMS=5000)\n",
    "            self._client.admin.command(\"ping\")\n",
    "            db = self._client[self.db_name]\n",
    "            self._collection = db[self.collection_name]\n",
    "            \n",
    "            self._collection.create_index(\"thread_id\")\n",
    "            self._collection.create_index(\"user_id\") \n",
    "            self._collection.create_index([(\"conversations.user_query\", \"text\")])\n",
    "            \n",
    "            logging.info(\"ThreadBasedProceduralMemory initialized successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to initialize MongoDB: {e}\")\n",
    "            self._client = None\n",
    "            self._collection = None\n",
    "    \n",
    "    def _is_connected(self) -> bool:\n",
    "        \"\"\"Check MongoDB connection\"\"\"\n",
    "        if self._client is None or self._collection is None:\n",
    "            return False\n",
    "        try:\n",
    "            self._client.admin.command(\"ping\")\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def store_thread_data(self, thread_id: str, profile_data: dict, \n",
    "                         user_query: str, ai_response: str, user_id: str = None) -> bool:\n",
    "        \"\"\"Store or update thread data with profile and conversation\"\"\"\n",
    "        if not self._is_connected():\n",
    "            logging.error(\"MongoDB not connected\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            from datetime import datetime\n",
    "            conversation_entry = {\n",
    "                \"timestamp\": datetime.utcnow().isoformat(),\n",
    "                \"user_query\": user_query[:1000],\n",
    "                \"ai_response\": ai_response[:3000],\n",
    "                \"query_type\": self._classify_query(user_query)\n",
    "            }\n",
    "            \n",
    "            existing_count = self._collection.count_documents({\"thread_id\": thread_id})\n",
    "            \n",
    "            if existing_count > 0:\n",
    "                update_data = {\n",
    "                    \"$set\": {\n",
    "                        \"last_updated\": datetime.utcnow().isoformat(),\n",
    "                        \"profile_data\": profile_data\n",
    "                    },\n",
    "                    \"$push\": {\n",
    "                        \"conversations\": conversation_entry\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                self._collection.update_one({\"thread_id\": thread_id}, update_data)\n",
    "                self._collection.update_one(\n",
    "                    {\"thread_id\": thread_id},\n",
    "                    {\"$push\": {\"conversations\": {\"$each\": [], \"$slice\": -50}}}\n",
    "                )\n",
    "                \n",
    "            else:\n",
    "                thread_data = {\n",
    "                    \"thread_id\": thread_id,\n",
    "                    \"user_id\": user_id or \"unknown\",\n",
    "                    \"created_at\": datetime.utcnow().isoformat(),\n",
    "                    \"last_updated\": datetime.utcnow().isoformat(),\n",
    "                    \"profile_data\": profile_data,\n",
    "                    \"conversations\": [conversation_entry]\n",
    "                }\n",
    "                \n",
    "                self._collection.insert_one(thread_data)\n",
    "            \n",
    "            logging.info(f\"Stored thread data for {thread_id}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to store thread data: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_similar_threads(self, query: str, current_thread_id: str = None, \n",
    "                          user_id: str = None, limit: int = 3) -> list[dict]:\n",
    "        \"\"\"Get similar threads based on query similarity\"\"\"\n",
    "        if not self._is_connected():\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            mongo_query = {}\n",
    "            if user_id:\n",
    "                mongo_query[\"user_id\"] = user_id\n",
    "            \n",
    "            if current_thread_id:\n",
    "                mongo_query[\"thread_id\"] = {\"$ne\": current_thread_id}\n",
    "            \n",
    "            cursor = self._collection.find(mongo_query).limit(limit * 2)\n",
    "            \n",
    "            results = []\n",
    "            query_words = set(query.lower().split())\n",
    "            \n",
    "            for thread in cursor:\n",
    "                score = 0\n",
    "                \n",
    "                for conv in thread.get(\"conversations\", [])[-5:]:\n",
    "                    conv_words = set(conv.get(\"user_query\", \"\").lower().split())\n",
    "                    overlap = len(query_words.intersection(conv_words))\n",
    "                    if overlap > 0:\n",
    "                        score += overlap * 2\n",
    "                \n",
    "                if score > 0:\n",
    "                    thread[\"similarity_score\"] = score\n",
    "                    results.append(thread)\n",
    "            \n",
    "            results.sort(key=lambda x: x.get(\"similarity_score\", 0), reverse=True)\n",
    "            results = results[:limit]\n",
    "            \n",
    "            logging.info(f\"Found {len(results)} similar threads for query: {query[:50]}\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to get similar threads: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_thread_data(self, thread_id: str) -> Optional[dict]:\n",
    "        \"\"\"Get complete thread data\"\"\"\n",
    "        if not self._is_connected():\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            thread_data = self._collection.find_one({\"thread_id\": thread_id})\n",
    "            if thread_data and \"_id\" in thread_data:\n",
    "                thread_data[\"_id\"] = str(thread_data[\"_id\"])\n",
    "            return thread_data\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to get thread data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _classify_query(self, query: str) -> str:\n",
    "        \"\"\"Classify the type of query for better matching\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        if any(word in query_lower for word in [\"career plan\", \"roadmap\", \"planning\"]):\n",
    "            return \"career_planning\"\n",
    "        elif any(word in query_lower for word in [\"switch\", \"transition\", \"change\"]):\n",
    "            return \"career_transition\"\n",
    "        elif any(word in query_lower for word in [\"skill\", \"learn\", \"course\"]):\n",
    "            return \"skill_development\"\n",
    "        elif any(word in query_lower for word in [\"resume\", \"profile\", \"linkedin\"]):\n",
    "            return \"profile_optimization\"\n",
    "        else:\n",
    "            return \"general_career\"\n",
    "\n",
    "# Initialize procedural memory\n",
    "thread_procedural_memory = ThreadBasedProceduralMemory()\n",
    "\n",
    "def build_enhanced_graph():\n",
    "    \"\"\"Build the enhanced graph with dual interrupt/resume segments\"\"\"\n",
    "    builder = StateGraph(AgentState)\n",
    "    \n",
    "    # SEGMENT 1: Routing nodes\n",
    "    builder.add_node(\"linkedin_scraper\", linkedin_scraper_node)\n",
    "    builder.add_node(\"career_qa_router\", career_qa_router)\n",
    "    builder.add_node(\"analyze_profile\", analyze_profile_node)\n",
    "    builder.add_node(\"job_fit_agent\", job_fit_agent_node)\n",
    "    builder.add_node(\"enhance_profile\", enhance_profile_node)\n",
    "    builder.add_node(\"general_qa_node\", general_qa_node)\n",
    "    \n",
    "    # SEGMENT 2: Career plan nodes\n",
    "    builder.add_node(\"career_plan_entry\", career_plan_entry_node)\n",
    "    builder.add_node(\"career_plan_generator\", career_plan_generator_node)\n",
    "    builder.add_node(\"career_plan_review\", career_plan_review_node)\n",
    "    \n",
    "    # Web search nodes (shared)\n",
    "    builder.add_node(\"websearch_mcp\", websearch_mcp_node)\n",
    "    builder.add_node(\"enrich_websearch\", enrich_websearch_node)\n",
    "    builder.add_node(\"store_websearch\", store_websearch_node)\n",
    "    \n",
    "    # Entry point\n",
    "    builder.set_entry_point(\"linkedin_scraper\")\n",
    "    \n",
    "    # SEGMENT 1 ROUTING: LinkedIn scraper -> Router -> 4 task nodes\n",
    "    builder.add_edge(\"linkedin_scraper\", \"career_qa_router\")\n",
    "    \n",
    "    # Router to task nodes\n",
    "    builder.add_edge(\"career_qa_router\", \"analyze_profile\")\n",
    "    builder.add_edge(\"career_qa_router\", \"job_fit_agent\")\n",
    "    builder.add_edge(\"career_qa_router\", \"enhance_profile\")\n",
    "    builder.add_edge(\"career_qa_router\", \"general_qa_node\")\n",
    "    \n",
    "    # Task nodes back to router for continued conversation\n",
    "    builder.add_edge(\"analyze_profile\", \"career_qa_router\")\n",
    "    builder.add_edge(\"job_fit_agent\", \"career_qa_router\")\n",
    "    builder.add_edge(\"enhance_profile\", \"career_qa_router\")\n",
    "    builder.add_edge(\"general_qa_node\", \"career_qa_router\")\n",
    "    \n",
    "    # SEGMENT 2 ROUTING: Career plan flow\n",
    "    builder.add_edge(\"career_plan_entry\", \"career_plan_generator\")\n",
    "    builder.add_edge(\"career_plan_entry\", \"websearch_mcp\")\n",
    "    \n",
    "    # Web search flow for career planning\n",
    "    builder.add_edge(\"websearch_mcp\", \"enrich_websearch\")\n",
    "    builder.add_edge(\"enrich_websearch\", \"store_websearch\")\n",
    "    builder.add_edge(\"store_websearch\", \"career_plan_generator\")\n",
    "    \n",
    "    # Career plan review cycle\n",
    "    builder.add_edge(\"career_plan_generator\", \"career_plan_review\")\n",
    "    builder.add_edge(\"career_plan_review\", \"career_plan_entry\")  # Can restart career planning\n",
    "\n",
    "    return builder.compile(checkpointer=memory)\n",
    "\n",
    "# Create the enhanced graph\n",
    "graph = build_enhanced_graph()\n",
    "\n",
    "def test_enhanced_functionality():\n",
    "    \"\"\"Test the enhanced dual-segment functionality\"\"\"\n",
    "    print(\"=== TESTING ENHANCED DUAL-SEGMENT GRAPH ===\")\n",
    "    \n",
    "    # Test routing segment\n",
    "    routing_test_state = {\n",
    "        \"messages\": [HumanMessage(content=\"Can you review my LinkedIn profile?\")],\n",
    "        \"profile_data\": {\n",
    "            \"headline\": \"Software Engineer at Tech Corp\", \n",
    "            \"skills\": [\"Python\", \"JavaScript\", \"React\"],\n",
    "            \"experience\": \"3 years\",\n",
    "            \"user_id\": \"test_user_routing\"\n",
    "        },\n",
    "        \"linkedin_url\": \"https://linkedin.com/in/testuser\",\n",
    "        \"thread_id\": \"routing_test_thread\",\n",
    "        \"profile_scraped\": True,\n",
    "        \"current_segment\": \"routing\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        result = graph.invoke(\n",
    "            routing_test_state,\n",
    "            config={\"configurable\": {\"thread_id\": \"routing_test_thread\"}}\n",
    "        )\n",
    "        print(\"✅ Routing segment test successful\")\n",
    "        print(f\"Messages: {len(result.get('messages', []))}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Routing segment test failed: {e}\")\n",
    "    \n",
    "    # Test career plan segment\n",
    "    career_plan_test_state = {\n",
    "        \"messages\": [HumanMessage(content=\"Create a 6-month plan to transition from software engineering to data science\")],\n",
    "        \"profile_data\": {\n",
    "            \"headline\": \"Software Engineer\", \n",
    "            \"skills\": [\"Python\", \"SQL\"],\n",
    "            \"user_id\": \"test_user_career\"\n",
    "        },\n",
    "        \"thread_id\": \"career_plan_test_thread\",\n",
    "        \"profile_scraped\": True,\n",
    "        \"current_segment\": \"career_plan\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Start from career plan entry\n",
    "        from langgraph.types import Command\n",
    "        \n",
    "        # This would trigger career plan generation\n",
    "        print(\"✅ Career plan segment structure verified\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Career plan segment test failed: {e}\")\n",
    "    \n",
    "    print(\"=== ENHANCED FUNCTIONALITY TEST COMPLETE ===\")\n",
    "\n",
    "# Export components\n",
    "__all__ = [\n",
    "    \"graph\", \n",
    "    \"memory\", \n",
    "    \"thread_procedural_memory\", \n",
    "    \"test_enhanced_functionality\",\n",
    "    \"AgentState\"\n",
    "]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_enhanced_functionality()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
